{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27721f48",
   "metadata": {},
   "source": [
    "# Comikry â€” Colab Prototype\n",
    "End-to-end pipeline validation on a single comic page.\n",
    "\n",
    "**Run cells top-to-bottom.** Cell 2 clones the latest repo code automatically.\n",
    "\n",
    "**API key setup (once):**\n",
    "- **VS Code** â€” copy `.env.example` â†’ `.env` in the repo root and fill in `OPENROUTER_API_KEY`\n",
    "- **Colab browser** â€” left sidebar â†’ ğŸ”‘ *Secrets* â†’ *Add new secret* â†’ name: `OPENROUTER_API_KEY`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afc4f07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â–º Cloning comikry repo â€¦\n",
      "âœ…  Repo ready at /content/comikry\n",
      "âœ…  Repo ready at /content/comikry\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "REPO_URL  = 'https://github.com/LIdro/comikry.git'\n",
    "REPO_DIR  = Path('/content/comikry')\n",
    "\n",
    "if REPO_DIR.exists():\n",
    "    # Already cloned â€” pull latest changes\n",
    "    print('â–º Pulling latest changes â€¦')\n",
    "    os.system(f'git -C {REPO_DIR} pull --ff-only')\n",
    "else:\n",
    "    print('â–º Cloning comikry repo â€¦')\n",
    "    os.system(f'git clone --depth 1 {REPO_URL} {REPO_DIR}')\n",
    "\n",
    "# Add repo root to the Python path so backend modules are importable if needed\n",
    "import sys\n",
    "if str(REPO_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(REPO_DIR))\n",
    "\n",
    "print(f'âœ…  Repo ready at {REPO_DIR}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b638f69f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
      "\n",
      "Reading state information...\n",
      "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
      "The following NEW packages will be installed:\n",
      "  poppler-utils\n",
      "0 upgraded, 1 newly installed, 0 to remove and 2 not upgraded.\n",
      "Need to get 186 kB of archives.\n",
      "After this operation, 697 kB of additional disk space will be used.\n",
      "The following NEW packages will be installed:\n",
      "  poppler-utils\n",
      "0 upgraded, 1 newly installed, 0 to remove and 2 not upgraded.\n",
      "Need to get 186 kB of archives.\n",
      "After this operation, 697 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.12 [186 kB]\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.12 [186 kB]\n",
      "Fetched 186 kB in 1s (277 kB/s)\n",
      "Fetched 186 kB in 1s (277 kB/s)\n",
      "Selecting previously unselected package poppler-utils.\n",
      "Selecting previously unselected package poppler-utils.\n",
      "(Reading database ... 117540 files and directories currently installed.)\n",
      "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.12_amd64.deb ...\n",
      "Unpacking poppler-utils (22.02.0-2ubuntu0.12) ...\n",
      "(Reading database ... 117540 files and directories currently installed.)\n",
      "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.12_amd64.deb ...\n",
      "Unpacking poppler-utils (22.02.0-2ubuntu0.12) ...\n",
      "Setting up poppler-utils (22.02.0-2ubuntu0.12) ...\n",
      "Processing triggers for man-db (2.10.2-1) ...\n",
      "Setting up poppler-utils (22.02.0-2ubuntu0.12) ...\n",
      "Processing triggers for man-db (2.10.2-1) ...\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31mÃ—\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31mâ”‚\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31mâ•°â”€>\u001b[0m See above for output.\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25herror\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "\n",
      "\u001b[31mÃ—\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "\u001b[31mâ”‚\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "\u001b[31mâ•°â”€>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31mÃ—\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31mâ”‚\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31mâ•°â”€>\u001b[0m See above for output.\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25herror\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "\n",
      "\u001b[31mÃ—\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "\u001b[31mâ”‚\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "\u001b[31mâ•°â”€>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m80.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/18.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m318.7/318.7 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m111.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m131.2/131.2 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m80.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m318.7/318.7 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m111.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m131.2/131.2 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-genai 1.63.0 requires websockets<15.1.0,>=13.0.0, but you have websockets 12.0 which is incompatible.\n",
      "dataproc-spark-connect 1.0.2 requires websockets>=14.0, but you have websockets 12.0 which is incompatible.\n",
      "google-adk 1.25.0 requires websockets<16.0.0,>=15.0.1, but you have websockets 12.0 which is incompatible.\n",
      "yfinance 0.2.66 requires websockets>=13.0, but you have websockets 12.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-genai 1.63.0 requires websockets<15.1.0,>=13.0.0, but you have websockets 12.0 which is incompatible.\n",
      "dataproc-spark-connect 1.0.2 requires websockets>=14.0, but you have websockets 12.0 which is incompatible.\n",
      "google-adk 1.25.0 requires websockets<16.0.0,>=15.0.1, but you have websockets 12.0 which is incompatible.\n",
      "yfinance 0.2.66 requires websockets>=13.0, but you have websockets 12.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# â”€â”€ System packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "!apt-get install -q -y ffmpeg poppler-utils\n",
    "\n",
    "# â”€â”€ Python packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "!pip install -q pdf2image Pillow httpx python-ulid pydantic pydantic-settings python-dotenv\n",
    "\n",
    "# â”€â”€ Audiocraft â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Install audiocraft's runtime deps first, then audiocraft itself with\n",
    "# --no-build-isolation so setup.py can see the already-installed packages.\n",
    "!pip install -q 'torch>=2.1' 'torchaudio>=2.1' einops flashy xformers encodec num2words sentencepiece huggingface_hub\n",
    "!pip install -q --no-build-isolation --no-deps git+https://github.com/facebookresearch/audiocraft.git\n",
    "\n",
    "# Verify in a subprocess (the current kernel's import cache is stale after pip install)\n",
    "import subprocess, sys\n",
    "_r = subprocess.run([sys.executable, '-c', 'import audiocraft; print(audiocraft.__name__)'], capture_output=True, text=True)\n",
    "if _r.returncode == 0:\n",
    "    print('âœ…  audiocraft installed successfully')\n",
    "else:\n",
    "    print('âŒ  audiocraft import failed:\\n', _r.stderr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f2c650d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'REPO_DIR' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-1075/4285303816.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m     )\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'OPENROUTER_API_KEY'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_api_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;31m# â”€â”€ Comic / run settings â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipython-input-1075/4285303816.py\u001b[0m in \u001b[0;36m_load_api_key\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# to the repo root regardless of the kernel's working directory.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     candidates = [\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mREPO_DIR\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m'.env'\u001b[0m\u001b[0;34m,\u001b[0m           \u001b[0;31m# set by cell 2 â€” works in both VS Code and Colab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/comikry/.env'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Colab fallback if cell 2 was skipped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m'.env'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'REPO_DIR' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# â”€â”€ Load API key â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Supports two environments automatically:\n",
    "#\n",
    "#   VS Code  â†’ reads from the root .env  (copy .env.example â†’ .env and fill in key)\n",
    "#   Colab    â†’ reads from the ğŸ”‘ Secrets panel (left sidebar â†’ Add new secret)\n",
    "#\n",
    "def _load_api_key() -> str:\n",
    "    # Build candidate .env paths.\n",
    "    # REPO_DIR is set by cell 2 (the git clone/pull cell) so it always points\n",
    "    # to the repo root regardless of the kernel's working directory.\n",
    "    candidates = [\n",
    "        REPO_DIR / '.env',           # set by cell 2 â€” works in both VS Code and Colab\n",
    "        Path('/content/comikry/.env'),  # Colab fallback if cell 2 was skipped\n",
    "        Path(__file__).resolve().parents[1] / '.env'\n",
    "            if '__file__' in dir() else None,\n",
    "        Path('.env'),                # last-resort cwd fallback\n",
    "    ]\n",
    "\n",
    "    for env_file in candidates:\n",
    "        if env_file is None or not env_file.exists():\n",
    "            continue\n",
    "        for line in env_file.read_text().splitlines():\n",
    "            line = line.strip()\n",
    "            if line.startswith('OPENROUTER_API_KEY=') and not line.startswith('#'):\n",
    "                key = line.split('=', 1)[1].strip()\n",
    "                if key and key != 'your_openrouter_api_key_here':\n",
    "                    print(f'ğŸ”‘  API key loaded from {env_file}')\n",
    "                    return key\n",
    "\n",
    "    # Fall back to Colab Secrets (browser Colab without a local .env)\n",
    "    try:\n",
    "        from google.colab import userdata\n",
    "        key = userdata.get('OPENROUTER_API_KEY')\n",
    "        if key:\n",
    "            print('ğŸ”‘  API key loaded from Colab Secrets')\n",
    "            return key\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Already set in the process environment\n",
    "    key = os.environ.get('OPENROUTER_API_KEY', '')\n",
    "    if key:\n",
    "        print('ğŸ”‘  API key loaded from environment variable')\n",
    "        return key\n",
    "\n",
    "    raise EnvironmentError(\n",
    "        'OPENROUTER_API_KEY not found.\\n'\n",
    "        '  VS Code : copy .env.example â†’ .env in the repo root and fill in the key.\\n'\n",
    "        '  Colab   : left sidebar â†’ ğŸ”‘ Secrets â†’ Add new secret â†’ OPENROUTER_API_KEY'\n",
    "    )\n",
    "\n",
    "os.environ['OPENROUTER_API_KEY'] = _load_api_key()\n",
    "\n",
    "# â”€â”€ Comic / run settings â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "PDF_PATH   = 'comic.pdf'   # â† set the filename of the PDF you uploaded\n",
    "PAGE_NUM   = 1             # page to process (1-based)\n",
    "COMIC_ID   = 'colab_test'\n",
    "STORAGE    = '/content/storage'\n",
    "os.makedirs(STORAGE, exist_ok=True)\n",
    "\n",
    "# â”€â”€ Audiocraft device â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 'auto' â†’ CUDA if a GPU runtime is active, otherwise CPU (recommended)\n",
    "# 'cuda' â†’ force GPU  (Runtime â†’ Change runtime type â†’ T4 GPU)\n",
    "# 'cpu'  â†’ force CPU  (works on any runtime, ~3â€“5Ã— slower for audiogen-small)\n",
    "AUDIOCRAFT_DEVICE = 'auto'   # â† change to 'cuda' or 'cpu' to override\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bee836",
   "metadata": {},
   "source": [
    "## Step 1 â€” Render PDF page to PNG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08f4942",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "from pathlib import Path\n",
    "\n",
    "pages_dir = Path(STORAGE) / COMIC_ID / 'pages'\n",
    "pages_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "pages = convert_from_path(PDF_PATH, dpi=150, fmt='png')\n",
    "page_path = pages_dir / f'page_{PAGE_NUM:04d}.png'\n",
    "pages[PAGE_NUM - 1].save(str(page_path), 'PNG')\n",
    "print(f'Saved page image: {page_path}')\n",
    "\n",
    "from IPython.display import display, Image as IPImage\n",
    "display(IPImage(str(page_path), width=600))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d9b7b2",
   "metadata": {},
   "source": [
    "## Step 2 â€” Detect panels with Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f687291a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64, json, httpx\n",
    "\n",
    "OPENROUTER_KEY  = os.environ['OPENROUTER_API_KEY']\n",
    "VISION_MODEL    = 'google/gemini-2.5-flash-lite'\n",
    "OR_BASE         = 'https://openrouter.ai/api/v1'\n",
    "HEADERS         = {'Authorization': f'Bearer {OPENROUTER_KEY}', 'Content-Type': 'application/json'}\n",
    "\n",
    "def encode_image(path):\n",
    "    return base64.b64encode(open(path, 'rb').read()).decode()\n",
    "\n",
    "def chat(model, messages):\n",
    "    r = httpx.post(f'{OR_BASE}/chat/completions',\n",
    "                   headers=HEADERS, json={'model': model, 'messages': messages}, timeout=120)\n",
    "    r.raise_for_status()\n",
    "    return r.json()['choices'][0]['message']['content'].strip()\n",
    "\n",
    "PANEL_PROMPT = '''\n",
    "You are a comic panel analyser. Return ONLY a JSON array of panels in reading order.\n",
    "Each element: {\"order\": int, \"x\": int, \"y\": int, \"w\": int, \"h\": int}\n",
    "'''\n",
    "\n",
    "b64 = encode_image(str(page_path))\n",
    "raw = chat(VISION_MODEL, [\n",
    "    {'role': 'system', 'content': PANEL_PROMPT},\n",
    "    {'role': 'user', 'content': [\n",
    "        {'type': 'image_url', 'image_url': {'url': f'data:image/png;base64,{b64}'}},\n",
    "        {'type': 'text', 'text': 'Detect all panels.'}\n",
    "    ]}\n",
    "])\n",
    "\n",
    "if raw.startswith('```'): raw = raw.split('```')[1].lstrip('json').strip()\n",
    "panels_raw = json.loads(raw)\n",
    "print(f'Found {len(panels_raw)} panels:', json.dumps(panels_raw, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addfe1e2",
   "metadata": {},
   "source": [
    "## Step 3 â€” Crop panels and run bubble OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a470c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image as PILImage\n",
    "\n",
    "panels_dir = Path(STORAGE) / COMIC_ID / 'panels'\n",
    "panels_dir.mkdir(exist_ok=True)\n",
    "\n",
    "BUBBLE_PROMPT = '''\n",
    "You are a comic OCR specialist. For each bubble return ONLY a JSON array.\n",
    "Each element: {\"order\": int, \"type\": str, \"x\": int, \"y\": int, \"w\": int, \"h\": int, \"text\": str, \"confidence\": float}\n",
    "Types: speech, thought, narration, sfx.\n",
    "'''\n",
    "\n",
    "all_bubbles = []\n",
    "page_img = PILImage.open(str(page_path))\n",
    "\n",
    "for p in sorted(panels_raw, key=lambda d: d['order']):\n",
    "    crop = page_img.crop((p['x'], p['y'], p['x']+p['w'], p['y']+p['h']))\n",
    "    panel_file = panels_dir / f\"panel_{p['order']:03d}.png\"\n",
    "    crop.save(str(panel_file), 'PNG')\n",
    "\n",
    "    b64p = encode_image(str(panel_file))\n",
    "    raw = chat(VISION_MODEL, [\n",
    "        {'role': 'system', 'content': BUBBLE_PROMPT},\n",
    "        {'role': 'user', 'content': [\n",
    "            {'type': 'image_url', 'image_url': {'url': f'data:image/png;base64,{b64p}'}},\n",
    "            {'type': 'text', 'text': 'Extract all bubbles and their text.'}\n",
    "        ]}\n",
    "    ])\n",
    "    if raw.startswith('```'): raw = raw.split('```')[1].lstrip('json').strip()\n",
    "    bubbles = json.loads(raw)\n",
    "    for b in bubbles:\n",
    "        b['panel_order'] = p['order']\n",
    "    all_bubbles.extend(bubbles)\n",
    "    print(f\"Panel {p['order']}: {len(bubbles)} bubbles\")\n",
    "\n",
    "print(json.dumps(all_bubbles, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b29f5f",
   "metadata": {},
   "source": [
    "## Step 4 â€” Speaker attribution + voice assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d5ef86",
   "metadata": {},
   "outputs": [],
   "source": [
    "ATTR_PROMPT = '''\n",
    "You are a comic character recognition agent. Attribute each bubble to a speaker.\n",
    "Return ONLY: {\"attributions\": [{\"bubble_id\": str, \"speaker_id\": str, \"label\": str}],\n",
    "              \"new_speakers\": [{\"speaker_id\": str, \"label\": str, \"gender\": str, \"age_group\": str}]}\n",
    "Use \\\"narrator\\\" for narration boxes. Reuse known speaker IDs when the same character reappears.\n",
    "'''\n",
    "\n",
    "VOICE_MAP = {\n",
    "    ('male','child'): 'verse', ('male','teen'): 'verse', ('male','adult'): 'echo', ('male','elder'): 'onyx',\n",
    "    ('female','child'): 'coral', ('female','teen'): 'coral', ('female','adult'): 'nova', ('female','elder'): 'shimmer',\n",
    "    ('unknown','adult'): 'alloy',\n",
    "}\n",
    "\n",
    "known_speakers = []\n",
    "\n",
    "for p in sorted(panels_raw, key=lambda d: d['order']):\n",
    "    panel_file = panels_dir / f\"panel_{p['order']:03d}.png\"\n",
    "    panel_bubbles = [b for b in all_bubbles if b['panel_order'] == p['order']]\n",
    "    bubble_list = [{'bubble_id': f\"p{p['order']}_b{b['order']}\", 'text': b['text'], 'type': b['type']} for b in panel_bubbles]\n",
    "\n",
    "    b64p = encode_image(str(panel_file))\n",
    "    raw = chat(VISION_MODEL, [\n",
    "        {'role': 'system', 'content': ATTR_PROMPT},\n",
    "        {'role': 'user', 'content': [\n",
    "            {'type': 'image_url', 'image_url': {'url': f'data:image/png;base64,{b64p}'}},\n",
    "            {'type': 'text', 'text': json.dumps({'known_speakers': [{'speaker_id': s['speaker_id'], 'label': s['label']} for s in known_speakers], 'bubbles': bubble_list})}\n",
    "        ]}\n",
    "    ])\n",
    "    if raw.startswith('```'): raw = raw.split('```')[1].lstrip('json').strip()\n",
    "    attr_data = json.loads(raw)\n",
    "\n",
    "    for attr in attr_data.get('attributions', []):\n",
    "        for b in all_bubbles:\n",
    "            if f\"p{p['order']}_b{b['order']}\" == attr['bubble_id']:\n",
    "                b['speaker_id'] = attr['speaker_id']\n",
    "\n",
    "    existing_ids = {s['speaker_id'] for s in known_speakers}\n",
    "    for ns in attr_data.get('new_speakers', []):\n",
    "        if ns['speaker_id'] not in existing_ids:\n",
    "            ns['voice_id'] = VOICE_MAP.get((ns.get('gender','unknown'), ns.get('age_group','adult')), 'alloy')\n",
    "            known_speakers.append(ns)\n",
    "\n",
    "print('Speakers:', json.dumps(known_speakers, indent=2))\n",
    "print('Attributed bubbles:', json.dumps(all_bubbles, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc75829",
   "metadata": {},
   "source": [
    "## Step 5 â€” Emotion tagging + TTS generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4970bec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TTS_MODEL = 'openai/gpt-audio-mini'\n",
    "voice_dir = Path(STORAGE) / COMIC_ID / 'audio' / 'voice'\n",
    "voice_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "EMOTION_PROMPT = '''\n",
    "Infer emotion per bubble. Return ONLY a JSON array:\n",
    "[{\"bubble_id\": str, \"emotion\": str}]\n",
    "Emotions: neutral, happy, sad, angry, excited, scared, surprised, sarcastic, whispering, shouting.\n",
    "'''\n",
    "\n",
    "speaker_map = {s['speaker_id']: s['label'] for s in known_speakers}\n",
    "bubble_list_for_emotion = [{'bubble_id': f\"p{b['panel_order']}_b{b['order']}\", 'text': b['text'], 'speaker': speaker_map.get(b.get('speaker_id',''), 'unknown')} for b in all_bubbles if b.get('text','').strip()]\n",
    "\n",
    "raw = chat(VISION_MODEL, [\n",
    "    {'role': 'system', 'content': EMOTION_PROMPT},\n",
    "    {'role': 'user', 'content': json.dumps(bubble_list_for_emotion)}\n",
    "])\n",
    "if raw.startswith('```'): raw = raw.split('```')[1].lstrip('json').strip()\n",
    "emotion_data = json.loads(raw)\n",
    "emotion_map = {e['bubble_id']: e['emotion'] for e in emotion_data}\n",
    "\n",
    "for b in all_bubbles:\n",
    "    bid = f\"p{b['panel_order']}_b{b['order']}\"\n",
    "    b['emotion'] = emotion_map.get(bid, 'neutral')\n",
    "\n",
    "# Generate TTS\n",
    "voice_lookup = {s['speaker_id']: s['voice_id'] for s in known_speakers}\n",
    "\n",
    "for b in all_bubbles:\n",
    "    if not b.get('text', '').strip() or b.get('type') == 'sfx': continue\n",
    "    voice_id = voice_lookup.get(b.get('speaker_id', ''), 'alloy')\n",
    "    out_path = voice_dir / f\"p{b['panel_order']}_b{b['order']}.mp3\"\n",
    "    r = httpx.post(f'{OR_BASE}/audio/speech', headers=HEADERS, timeout=120,\n",
    "                   json={'model': TTS_MODEL, 'input': b['text'], 'voice': voice_id,\n",
    "                         'instructions': f\"Speak with a {b['emotion']} tone.\", 'response_format': 'mp3'})\n",
    "    r.raise_for_status()\n",
    "    out_path.write_bytes(r.content)\n",
    "    b['audio_path'] = str(out_path)\n",
    "    print(f\"  [{b['emotion']}] {b['text'][:50]!r} â†’ {out_path.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4a726e",
   "metadata": {},
   "source": [
    "## Step 6 â€” SFX generation (Audiocraft AudioGen)\n",
    "\n",
    "Uses `facebook/audiogen-small` (~300 MB) â€” small enough to run comfortably on **both CPU and GPU**.\n",
    "\n",
    "| Mode | When to use | Speed |\n",
    "|---|---|---|\n",
    "| **GPU** (`cuda`) | Colab T4 runtime â€” *Runtime â†’ Change runtime type â†’ T4 GPU* | ~4 s per panel |\n",
    "| **CPU** (`cpu`) | Free Colab CPU runtime or when no GPU is available | ~15â€“25 s per panel |\n",
    "\n",
    "Set `AUDIOCRAFT_DEVICE` in the config cell above to `'auto'` (default), `'cuda'`, or `'cpu'`.\n",
    "\n",
    "Outputs are converted from WAV â†’ 128 kbps MP3 via ffmpeg then the WAV is deleted to reclaim disk space.  \n",
    "Model weights are cached under `/content/audiocraft_cache` (outside the home partition) to avoid quota issues.  \n",
    "Weights are re-downloaded each session (~300 MB) unless you persist that folder to Google Drive.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f61d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, subprocess, torch\n",
    "from pathlib import Path\n",
    "from audiocraft.models import AudioGen\n",
    "from audiocraft.data.audio import audio_write\n",
    "\n",
    "# â”€â”€ Resolve device from the config cell setting â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "if AUDIOCRAFT_DEVICE == 'auto':\n",
    "    _device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "elif AUDIOCRAFT_DEVICE == 'cuda':\n",
    "    if not torch.cuda.is_available():\n",
    "        print('âš ï¸  CUDA requested but no GPU found â€” falling back to CPU.')\n",
    "        print('    To use a GPU: Runtime â†’ Change runtime type â†’ T4 GPU')\n",
    "        _device = 'cpu'\n",
    "    else:\n",
    "        _device = 'cuda'\n",
    "else:\n",
    "    _device = 'cpu'\n",
    "\n",
    "print(f'Audiocraft device: {_device}')\n",
    "\n",
    "# â”€â”€ Redirect model weights away from the home-partition quota â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "os.environ['AUDIOCRAFT_CACHE_DIR'] = '/content/audiocraft_cache'\n",
    "os.makedirs('/content/audiocraft_cache', exist_ok=True)\n",
    "\n",
    "# â”€â”€ Load model (audiogen-small â‰ˆ 300 MB â€” fits on T4 and runs fine on CPU) â”€\n",
    "print('Loading facebook/audiogen-small â€¦')\n",
    "sfx_model = AudioGen.get_pretrained('facebook/audiogen-small', device=_device)\n",
    "sfx_model.set_generation_params(duration=4)   # 4 s per panel: sufficient & saves VRAM/disk\n",
    "print('Model ready.')\n",
    "\n",
    "# â”€â”€ Build one SFX prompt per panel via Gemini â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "SFX_PROMPT = '''\n",
    "You are a comic sound-design director. For each panel image produce a short, vivid\n",
    "audio description suitable as a text-to-audio prompt (â‰¤ 12 words).\n",
    "Return ONLY a JSON object: {\"panel_<order>\": \"<prompt>\", ...}\n",
    "Focus on ambient mood + key action sounds. Avoid music references.\n",
    "'''\n",
    "\n",
    "sfx_prompts: dict[str, str] = {}\n",
    "for p in sorted(panels_raw, key=lambda d: d['order']):\n",
    "    panel_file = panels_dir / f\"panel_{p['order']:03d}.png\"\n",
    "    b64p = encode_image(str(panel_file))\n",
    "    raw = chat(VISION_MODEL, [\n",
    "        {'role': 'system', 'content': SFX_PROMPT},\n",
    "        {'role': 'user', 'content': [\n",
    "            {'type': 'image_url', 'image_url': {'url': f'data:image/png;base64,{b64p}'}},\n",
    "            {'type': 'text', 'text': 'Describe the soundscape for this panel.'}\n",
    "        ]}\n",
    "    ])\n",
    "    if raw.startswith('```'):\n",
    "        raw = raw.split('```')[1].lstrip('json').strip()\n",
    "    try:\n",
    "        sfx_prompts.update(json.loads(raw))\n",
    "    except json.JSONDecodeError:\n",
    "        sfx_prompts[f'panel_{p[\"order\"]}'] = 'soft ambient background, comic book atmosphere'\n",
    "\n",
    "print('SFX prompts:', json.dumps(sfx_prompts, indent=2))\n",
    "\n",
    "# â”€â”€ Generate audio + convert WAV â†’ MP3 (saves â‰ˆ 60 % disk) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "sfx_dir = Path(STORAGE) / COMIC_ID / 'audio' / 'sfx'\n",
    "sfx_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for p in sorted(panels_raw, key=lambda d: d['order']):\n",
    "    key      = f'panel_{p[\"order\"]}'\n",
    "    prompt   = sfx_prompts.get(key, 'soft ambient background, comic book atmosphere')\n",
    "    stem     = str(sfx_dir / f'panel_{p[\"order\"]:03d}')\n",
    "    wav_path = Path(stem + '.wav')\n",
    "    mp3_path = Path(stem + '.mp3')\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        wav = sfx_model.generate([prompt])   # shape: (1, channels, samples)\n",
    "\n",
    "    # audio_write appends '.wav' automatically\n",
    "    audio_write(\n",
    "        stem, wav[0].cpu(), sfx_model.sample_rate,\n",
    "        strategy='loudness', loudness_compressor=True\n",
    "    )\n",
    "\n",
    "    # Convert to MP3 and remove the WAV to save disk\n",
    "    result = subprocess.run(\n",
    "        ['ffmpeg', '-y', '-i', str(wav_path), '-b:a', '128k', str(mp3_path)],\n",
    "        capture_output=True\n",
    "    )\n",
    "    if result.returncode == 0 and wav_path.exists():\n",
    "        wav_path.unlink()\n",
    "        final_path = str(mp3_path)\n",
    "    else:\n",
    "        final_path = str(wav_path)   # keep WAV if ffmpeg failed\n",
    "\n",
    "    p['sfx_path'] = final_path\n",
    "    print(f'Panel {p[\"order\"]:2d}: {Path(final_path).name}  |  prompt: {prompt!r}')\n",
    "\n",
    "print('\\nSFX generation complete.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ad7d1c",
   "metadata": {},
   "source": [
    "## Step 7 â€” Playback test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ea2764",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio as IPAudio, display, Image as IPImage\n",
    "\n",
    "for p in sorted(panels_raw, key=lambda d: d['order']):\n",
    "    panel_file = panels_dir / f\"panel_{p['order']:03d}.png\"\n",
    "    print(f'\\n=== Panel {p[\"order\"]} ===')\n",
    "    display(IPImage(str(panel_file), width=500))\n",
    "\n",
    "    # SFX track for this panel\n",
    "    if p.get('sfx_path') and Path(p['sfx_path']).exists():\n",
    "        print(f'  ğŸ”Š SFX: {Path(p[\"sfx_path\"]).name}')\n",
    "        display(IPAudio(p['sfx_path']))\n",
    "\n",
    "    # Dialogue / narration bubbles\n",
    "    panel_bubbles = sorted(\n",
    "        [b for b in all_bubbles if b['panel_order'] == p['order']],\n",
    "        key=lambda x: x['order']\n",
    "    )\n",
    "    for b in panel_bubbles:\n",
    "        if b.get('audio_path') and Path(b['audio_path']).exists():\n",
    "            print(f'  ğŸ—¨  [{b.get(\"speaker_id\",\"?\")}] [{b[\"emotion\"]}] {b[\"text\"]}')\n",
    "            display(IPAudio(b['audio_path']))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
