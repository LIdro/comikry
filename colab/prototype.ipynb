{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27721f48",
   "metadata": {},
   "source": [
    "# Comikry â€” Colab Prototype\n",
    "End-to-end pipeline validation on a single comic page.\n",
    "\n",
    "**Run cells top-to-bottom.** Cell 2 clones the latest repo code automatically.\n",
    "\n",
    "**API key setup (once):**\n",
    "- **VS Code** â€” copy `.env.example` â†’ `.env` in the repo root and fill in `OPENROUTER_API_KEY`\n",
    "- **Colab browser** â€” left sidebar â†’ ğŸ”‘ *Secrets* â†’ *Add new secret* â†’ name: `OPENROUTER_API_KEY`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afc4f07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â–º Cloning comikry repo â€¦\n",
      "âœ…  Repo ready at /content/comikry\n",
      "âœ…  Repo ready at /content/comikry\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "REPO_URL  = 'https://github.com/LIdro/comikry.git'\n",
    "REPO_DIR  = Path('/content/comikry')\n",
    "\n",
    "if REPO_DIR.exists():\n",
    "    # Already cloned â€” pull latest changes\n",
    "    print('â–º Pulling latest changes â€¦')\n",
    "    os.system(f'git -C {REPO_DIR} pull --ff-only')\n",
    "else:\n",
    "    print('â–º Cloning comikry repo â€¦')\n",
    "    os.system(f'git clone --depth 1 {REPO_URL} {REPO_DIR}')\n",
    "\n",
    "# Add repo root to the Python path so backend modules are importable if needed\n",
    "import sys\n",
    "if str(REPO_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(REPO_DIR))\n",
    "\n",
    "print(f'âœ…  Repo ready at {REPO_DIR}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b638f69f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
      "\n",
      "Reading state information...\n",
      "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
      "The following NEW packages will be installed:\n",
      "  poppler-utils\n",
      "0 upgraded, 1 newly installed, 0 to remove and 2 not upgraded.\n",
      "Need to get 186 kB of archives.\n",
      "After this operation, 697 kB of additional disk space will be used.\n",
      "The following NEW packages will be installed:\n",
      "  poppler-utils\n",
      "0 upgraded, 1 newly installed, 0 to remove and 2 not upgraded.\n",
      "Need to get 186 kB of archives.\n",
      "After this operation, 697 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.12 [186 kB]\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.12 [186 kB]\n",
      "Fetched 186 kB in 1s (277 kB/s)\n",
      "Fetched 186 kB in 1s (277 kB/s)\n",
      "Selecting previously unselected package poppler-utils.\n",
      "Selecting previously unselected package poppler-utils.\n",
      "(Reading database ... 117540 files and directories currently installed.)\n",
      "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.12_amd64.deb ...\n",
      "Unpacking poppler-utils (22.02.0-2ubuntu0.12) ...\n",
      "(Reading database ... 117540 files and directories currently installed.)\n",
      "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.12_amd64.deb ...\n",
      "Unpacking poppler-utils (22.02.0-2ubuntu0.12) ...\n",
      "Setting up poppler-utils (22.02.0-2ubuntu0.12) ...\n",
      "Processing triggers for man-db (2.10.2-1) ...\n",
      "Setting up poppler-utils (22.02.0-2ubuntu0.12) ...\n",
      "Processing triggers for man-db (2.10.2-1) ...\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31mÃ—\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31mâ”‚\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31mâ•°â”€>\u001b[0m See above for output.\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25herror\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "\n",
      "\u001b[31mÃ—\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "\u001b[31mâ”‚\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "\u001b[31mâ•°â”€>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31mÃ—\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31mâ”‚\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31mâ•°â”€>\u001b[0m See above for output.\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25herror\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "\n",
      "\u001b[31mÃ—\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "\u001b[31mâ”‚\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "\u001b[31mâ•°â”€>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m80.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/18.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m318.7/318.7 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m111.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m131.2/131.2 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m80.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m318.7/318.7 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m111.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m131.2/131.2 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-genai 1.63.0 requires websockets<15.1.0,>=13.0.0, but you have websockets 12.0 which is incompatible.\n",
      "dataproc-spark-connect 1.0.2 requires websockets>=14.0, but you have websockets 12.0 which is incompatible.\n",
      "google-adk 1.25.0 requires websockets<16.0.0,>=15.0.1, but you have websockets 12.0 which is incompatible.\n",
      "yfinance 0.2.66 requires websockets>=13.0, but you have websockets 12.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-genai 1.63.0 requires websockets<15.1.0,>=13.0.0, but you have websockets 12.0 which is incompatible.\n",
      "dataproc-spark-connect 1.0.2 requires websockets>=14.0, but you have websockets 12.0 which is incompatible.\n",
      "google-adk 1.25.0 requires websockets<16.0.0,>=15.0.1, but you have websockets 12.0 which is incompatible.\n",
      "yfinance 0.2.66 requires websockets>=13.0, but you have websockets 12.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# â”€â”€ System packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "!apt-get install -q -y ffmpeg poppler-utils\n",
    "\n",
    "# â”€â”€ Python packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "!pip install -q pdf2image Pillow httpx python-ulid pydantic pydantic-settings python-dotenv ipywidgets\n",
    "\n",
    "# â”€â”€ Audiocraft â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Because we install with --no-deps, every transitive import audiocraft\n",
    "# touches at init must be listed here explicitly.\n",
    "!pip install -q \\\n",
    "    'torch>=2.1' 'torchaudio>=2.1' \\\n",
    "    av julius einops flashy xformers encodec \\\n",
    "    num2words sentencepiece huggingface_hub lameenc \\\n",
    "    hydra-core hydra-colorlog \\\n",
    "    demucs torchmetrics torchdiffeq \\\n",
    "    'numpy<2'\n",
    "\n",
    "!pip install -q --no-build-isolation --no-deps git+https://github.com/facebookresearch/audiocraft.git\n",
    "\n",
    "# Verify in a subprocess (kernel import cache is stale right after pip install)\n",
    "import subprocess, sys\n",
    "_r = subprocess.run([sys.executable, '-c', 'import audiocraft; print(audiocraft.__name__)'], capture_output=True, text=True)\n",
    "if _r.returncode == 0:\n",
    "    print('âœ…  audiocraft installed successfully')\n",
    "else:\n",
    "    print('âŒ  audiocraft import failed:\\n', _r.stderr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf043d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ OPTIONAL â€” run this cell only if you want to use Colab as a GPU SFX server â”€â”€\n",
    "# The rest of the notebook works fine without it.\n",
    "#\n",
    "# When you run this cell it will:\n",
    "#   1. Start a tiny FastAPI server in a background thread that generates SFX\n",
    "#      audio using AudioGen on this Colab GPU.\n",
    "#   2. Expose it publicly via the Colab tunnel (or ngrok as fallback).\n",
    "#   3. Print a SFX_API_URL you can paste into your local .env so the backend\n",
    "#      delegates SFX generation to this Colab instance instead of running\n",
    "#      AudioGen locally.\n",
    "\n",
    "import subprocess, sys, threading\n",
    "\n",
    "# Install server dependencies (quiet)\n",
    "subprocess.run([sys.executable, '-m', 'pip', 'install', '-q', 'uvicorn', 'fastapi', 'pyngrok'], check=False)\n",
    "\n",
    "import io, subprocess as _sp, tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "from fastapi import FastAPI\n",
    "from fastapi.responses import Response\n",
    "\n",
    "sfx_server_app = FastAPI(title='Colab SFX API')\n",
    "_sfx_server_model = None   # lazy-loaded on first request\n",
    "\n",
    "\n",
    "def _get_sfx_model():\n",
    "    global _sfx_server_model\n",
    "    if _sfx_server_model is not None:\n",
    "        return _sfx_server_model\n",
    "    import torch\n",
    "    from audiocraft.models import AudioGen  # type: ignore\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    _sfx_server_model = AudioGen.get_pretrained('facebook/audiogen-small', device=device)\n",
    "    _sfx_server_model.set_generation_params(duration=4)\n",
    "    return _sfx_server_model\n",
    "\n",
    "\n",
    "@sfx_server_app.post('/generate-sfx')\n",
    "async def generate_sfx_endpoint(body: dict):\n",
    "    \"\"\"Generate SFX audio and return raw MP3 bytes.\"\"\"\n",
    "    import asyncio, torch\n",
    "    from audiocraft.data.audio import audio_write  # type: ignore\n",
    "\n",
    "    prompt: str = body.get('prompt', 'ambient background')\n",
    "    duration: int = int(body.get('duration', 4))\n",
    "\n",
    "    model = _get_sfx_model()\n",
    "    model.set_generation_params(duration=duration)\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        wav = model.generate([prompt])\n",
    "\n",
    "    with tempfile.TemporaryDirectory() as tmpdir:\n",
    "        stem = str(Path(tmpdir) / 'sfx')\n",
    "        audio_write(stem, wav[0].cpu(), model.sample_rate,\n",
    "                    strategy='loudness', loudness_compressor=True)\n",
    "        wav_path = Path(stem + '.wav')\n",
    "        mp3_path = Path(stem + '.mp3')\n",
    "        result = _sp.run(\n",
    "            ['ffmpeg', '-y', '-i', str(wav_path), '-b:a', '128k', str(mp3_path)],\n",
    "            capture_output=True\n",
    "        )\n",
    "        if result.returncode == 0 and mp3_path.exists():\n",
    "            audio_bytes = mp3_path.read_bytes()\n",
    "        else:\n",
    "            audio_bytes = wav_path.read_bytes()\n",
    "\n",
    "    return Response(content=audio_bytes, media_type='audio/mpeg')\n",
    "\n",
    "\n",
    "# â”€â”€ Start uvicorn in a daemon background thread â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def _start_server():\n",
    "    import uvicorn\n",
    "    uvicorn.run(sfx_server_app, host='0.0.0.0', port=8000, log_level='warning')\n",
    "\n",
    "_server_thread = threading.Thread(target=_start_server, daemon=True)\n",
    "_server_thread.start()\n",
    "\n",
    "import time; time.sleep(2)   # give uvicorn a moment to bind\n",
    "\n",
    "# â”€â”€ Expose via Colab tunnel (fall back to ngrok) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "public_url = None\n",
    "\n",
    "try:\n",
    "    from google.colab.output import eval_js  # type: ignore\n",
    "    public_url = eval_js('google.colab.kernel.proxyPort(8000)')\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "if not public_url:\n",
    "    try:\n",
    "        from pyngrok import ngrok  # type: ignore\n",
    "        tunnel = ngrok.connect(8000)\n",
    "        public_url = tunnel.public_url\n",
    "    except Exception as e:\n",
    "        print(f'âš ï¸  Could not create tunnel: {e}')\n",
    "\n",
    "if public_url:\n",
    "    print(f'ğŸš€ SFX API running at: {public_url}')\n",
    "    print(f'Add to your local .env:  SFX_API_URL={public_url}')\n",
    "else:\n",
    "    print('âš ï¸  Server started locally on port 8000 but no public URL was obtained.')\n",
    "    print('    Try running: from pyngrok import ngrok; print(ngrok.connect(8000).public_url)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2c650d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'REPO_DIR' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-1075/4285303816.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m     )\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'OPENROUTER_API_KEY'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_api_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;31m# â”€â”€ Comic / run settings â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipython-input-1075/4285303816.py\u001b[0m in \u001b[0;36m_load_api_key\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# to the repo root regardless of the kernel's working directory.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     candidates = [\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mREPO_DIR\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m'.env'\u001b[0m\u001b[0;34m,\u001b[0m           \u001b[0;31m# set by cell 2 â€” works in both VS Code and Colab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/comikry/.env'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Colab fallback if cell 2 was skipped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m'.env'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'REPO_DIR' is not defined"
     ]
    }
   ],
   "source": [
    "import os, shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# â”€â”€ Upload comic PDF â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "UPLOAD_DIR = Path('/content/uploads')\n",
    "UPLOAD_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def _upload_pdf() -> str:\n",
    "    \"\"\"Upload a PDF via the UI and return its path.\"\"\"\n",
    "\n",
    "    # â”€â”€ Colab browser: native upload dialog â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    try:\n",
    "        from google.colab import files\n",
    "        print('ğŸ“‚  Choose a comic PDF to upload â€¦')\n",
    "        uploaded = files.upload()          # opens browser file picker\n",
    "        if not uploaded:\n",
    "            raise RuntimeError('No file selected.')\n",
    "        fname = next(iter(uploaded))\n",
    "        dest = UPLOAD_DIR / fname\n",
    "        dest.write_bytes(uploaded[fname])\n",
    "        print(f'âœ…  Uploaded â†’ {dest}')\n",
    "        return str(dest)\n",
    "    except ImportError:\n",
    "        pass  # not running in Colab browser â€” fall through\n",
    "\n",
    "    # â”€â”€ VS Code / Jupyter: ipywidgets file upload â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    try:\n",
    "        import ipywidgets as widgets\n",
    "        from IPython.display import display\n",
    "\n",
    "        uploader = widgets.FileUpload(accept='.pdf', multiple=False,\n",
    "                                      description='Upload PDF')\n",
    "        done_btn = widgets.Button(description='Continue â–¶',\n",
    "                                  button_style='success', disabled=True)\n",
    "        status   = widgets.HTML(value='<i>Select a PDF file above, then click Continue.</i>')\n",
    "\n",
    "        uploaded_path = [None]   # mutable container for the callback\n",
    "\n",
    "        def _on_upload(change):\n",
    "            for info in uploader.value:\n",
    "                dest = UPLOAD_DIR / info['name']\n",
    "                dest.write_bytes(info['content'].tobytes())\n",
    "                uploaded_path[0] = str(dest)\n",
    "                status.value = f'âœ… <b>{info[\"name\"]}</b> ready ({dest.stat().st_size / 1024:.0f} KB)'\n",
    "                done_btn.disabled = False\n",
    "\n",
    "        uploader.observe(_on_upload, names='value')\n",
    "\n",
    "        # Block until the user clicks Continue\n",
    "        import threading\n",
    "        event = threading.Event()\n",
    "        def _on_done(_):\n",
    "            event.set()\n",
    "        done_btn.on_click(_on_done)\n",
    "\n",
    "        display(widgets.VBox([uploader, done_btn, status]))\n",
    "        print('â³  Waiting for PDF upload â€¦')\n",
    "        event.wait()\n",
    "\n",
    "        if uploaded_path[0]:\n",
    "            print(f'âœ…  Uploaded â†’ {uploaded_path[0]}')\n",
    "            return uploaded_path[0]\n",
    "    except ImportError:\n",
    "        pass  # ipywidgets not available\n",
    "\n",
    "    # â”€â”€ Fallback: manual path entry â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    path = input('Enter the full path to your comic PDF: ').strip()\n",
    "    if not Path(path).exists():\n",
    "        raise FileNotFoundError(f'File not found: {path}')\n",
    "    return path\n",
    "\n",
    "PDF_PATH = _upload_pdf()\n",
    "\n",
    "# â”€â”€ Page-range selection â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "from pdf2image import pdfinfo_from_path as _pdfinfo\n",
    "\n",
    "_pdf_info   = _pdfinfo(PDF_PATH)\n",
    "_total_pages = _pdf_info['Pages']\n",
    "print(f'ğŸ“„  PDF has {_total_pages} page(s).')\n",
    "\n",
    "try:\n",
    "    import ipywidgets as widgets\n",
    "    from IPython.display import display\n",
    "    import threading as _threading\n",
    "\n",
    "    _range_slider = widgets.IntRangeSlider(\n",
    "        value=(1, min(5, _total_pages)),\n",
    "        min=1,\n",
    "        max=_total_pages,\n",
    "        step=1,\n",
    "        description='Pages:',\n",
    "        continuous_update=False,\n",
    "        layout=widgets.Layout(width='60%'),\n",
    "    )\n",
    "    _confirm_btn = widgets.Button(\n",
    "        description='Confirm â–¶',\n",
    "        button_style='success',\n",
    "    )\n",
    "    _range_label = widgets.HTML(\n",
    "        value=f'Will process pages <b>{_range_slider.value[0]}â€“{_range_slider.value[1]}</b>'\n",
    "    )\n",
    "\n",
    "    def _on_slider_change(change):\n",
    "        v = change['new']\n",
    "        _range_label.value = f'Will process pages <b>{v[0]}â€“{v[1]}</b>'\n",
    "\n",
    "    _range_slider.observe(_on_slider_change, names='value')\n",
    "\n",
    "    _range_event = _threading.Event()\n",
    "    _confirmed_range = [None]\n",
    "\n",
    "    def _on_confirm(_):\n",
    "        _confirmed_range[0] = tuple(_range_slider.value)\n",
    "        _range_event.set()\n",
    "\n",
    "    _confirm_btn.on_click(_on_confirm)\n",
    "\n",
    "    display(widgets.VBox([_range_slider, _range_label, _confirm_btn]))\n",
    "    print('â³  Select a page range and click Confirm â–¶ â€¦')\n",
    "    _range_event.wait()\n",
    "\n",
    "    PAGE_RANGE = _confirmed_range[0]\n",
    "except ImportError:\n",
    "    # ipywidgets not available â€” default to all pages\n",
    "    PAGE_RANGE = (1, _total_pages)\n",
    "\n",
    "print(f'âœ…  Processing pages {PAGE_RANGE[0]}â€“{PAGE_RANGE[1]} of {_total_pages}')\n",
    "\n",
    "# â”€â”€ Load API key â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Supports two environments automatically:\n",
    "#\n",
    "#   VS Code  â†’ reads from the root .env  (copy .env.example â†’ .env and fill in key)\n",
    "#   Colab    â†’ reads from the ğŸ”‘ Secrets panel (left sidebar â†’ Add new secret)\n",
    "#\n",
    "REPO_DIR = Path('/content/comikry')\n",
    "\n",
    "def _load_api_key() -> str:\n",
    "    candidates = [\n",
    "        REPO_DIR / '.env',\n",
    "        Path('/content/comikry/.env'),\n",
    "        Path(__file__).resolve().parents[1] / '.env'\n",
    "            if '__file__' in dir() else None,\n",
    "        Path('.env'),\n",
    "    ]\n",
    "\n",
    "    for env_file in candidates:\n",
    "        if env_file is None or not env_file.exists():\n",
    "            continue\n",
    "        for line in env_file.read_text().splitlines():\n",
    "            line = line.strip()\n",
    "            if line.startswith('OPENROUTER_API_KEY=') and not line.startswith('#'):\n",
    "                key = line.split('=', 1)[1].strip()\n",
    "                if key and key != 'your_openrouter_api_key_here':\n",
    "                    print(f'ğŸ”‘  API key loaded from {env_file}')\n",
    "                    return key\n",
    "\n",
    "    try:\n",
    "        from google.colab import userdata\n",
    "        key = userdata.get('OPENROUTER_API_KEY')\n",
    "        if key:\n",
    "            print('ğŸ”‘  API key loaded from Colab Secrets')\n",
    "            return key\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    key = os.environ.get('OPENROUTER_API_KEY', '')\n",
    "    if key:\n",
    "        print('ğŸ”‘  API key loaded from environment variable')\n",
    "        return key\n",
    "\n",
    "    raise EnvironmentError(\n",
    "        'OPENROUTER_API_KEY not found.\\n'\n",
    "        '  VS Code : copy .env.example â†’ .env in the repo root and fill in the key.\\n'\n",
    "        '  Colab   : left sidebar â†’ ğŸ”‘ Secrets â†’ Add new secret â†’ OPENROUTER_API_KEY'\n",
    "    )\n",
    "\n",
    "os.environ['OPENROUTER_API_KEY'] = _load_api_key()\n",
    "\n",
    "# â”€â”€ Run settings â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "COMIC_ID   = 'colab_test'\n",
    "STORAGE    = '/content/storage'\n",
    "os.makedirs(STORAGE, exist_ok=True)\n",
    "\n",
    "# â”€â”€ Audiocraft device â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 'auto' â†’ CUDA if a GPU runtime is active, otherwise CPU (recommended)\n",
    "# 'cuda' â†’ force GPU  (Runtime â†’ Change runtime type â†’ T4 GPU)\n",
    "# 'cpu'  â†’ force CPU  (works on any runtime, ~3â€“5Ã— slower for audiogen-small)\n",
    "AUDIOCRAFT_DEVICE = 'auto'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bee836",
   "metadata": {},
   "source": [
    "## Step 1 â€” Render PDF page to PNG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08f4942",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "from pathlib import Path\n",
    "from IPython.display import display, Image as IPImage\n",
    "\n",
    "pages_dir = Path(STORAGE) / COMIC_ID / 'pages'\n",
    "pages_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Use PAGE_RANGE set in the config cell above\n",
    "_first, _last = PAGE_RANGE\n",
    "print(f'ğŸ“„  Rendering pages {_first}â€“{_last} from {Path(PDF_PATH).name} â€¦')\n",
    "\n",
    "pages = convert_from_path(\n",
    "    PDF_PATH,\n",
    "    dpi=150,\n",
    "    fmt='png',\n",
    "    first_page=_first,\n",
    "    last_page=_last,\n",
    ")\n",
    "\n",
    "# Save all rendered pages\n",
    "page_paths = []\n",
    "for i, page_img in enumerate(pages):\n",
    "    page_num = _first + i\n",
    "    page_path = pages_dir / f'page_{page_num:04d}.png'\n",
    "    page_img.save(str(page_path), 'PNG')\n",
    "    page_paths.append(page_path)\n",
    "\n",
    "print(f'âœ…  Saved {len(page_paths)} page image(s) to {pages_dir}')\n",
    "print('   Pages:', [p.name for p in page_paths])\n",
    "\n",
    "# Display the first page as a preview\n",
    "if page_paths:\n",
    "    display(IPImage(str(page_paths[0]), width=600))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d9b7b2",
   "metadata": {},
   "source": [
    "## Step 2 â€” Detect panels with Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f687291a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64, json, httpx\n",
    "\n",
    "OPENROUTER_KEY  = os.environ['OPENROUTER_API_KEY']\n",
    "VISION_MODEL    = 'google/gemini-2.5-flash-lite'\n",
    "OR_BASE         = 'https://openrouter.ai/api/v1'\n",
    "HEADERS         = {'Authorization': f'Bearer {OPENROUTER_KEY}', 'Content-Type': 'application/json'}\n",
    "\n",
    "def encode_image(path):\n",
    "    return base64.b64encode(open(path, 'rb').read()).decode()\n",
    "\n",
    "def chat(model, messages):\n",
    "    r = httpx.post(f'{OR_BASE}/chat/completions',\n",
    "                   headers=HEADERS, json={'model': model, 'messages': messages}, timeout=120)\n",
    "    r.raise_for_status()\n",
    "    return r.json()['choices'][0]['message']['content'].strip()\n",
    "\n",
    "PANEL_PROMPT = '''\n",
    "You are a comic panel analyser. Return ONLY a JSON array of panels in reading order.\n",
    "Each element: {\"order\": int, \"x\": int, \"y\": int, \"w\": int, \"h\": int}\n",
    "'''\n",
    "\n",
    "b64 = encode_image(str(page_path))\n",
    "raw = chat(VISION_MODEL, [\n",
    "    {'role': 'system', 'content': PANEL_PROMPT},\n",
    "    {'role': 'user', 'content': [\n",
    "        {'type': 'image_url', 'image_url': {'url': f'data:image/png;base64,{b64}'}},\n",
    "        {'type': 'text', 'text': 'Detect all panels.'}\n",
    "    ]}\n",
    "])\n",
    "\n",
    "if raw.startswith('```'): raw = raw.split('```')[1].lstrip('json').strip()\n",
    "panels_raw = json.loads(raw)\n",
    "print(f'Found {len(panels_raw)} panels:', json.dumps(panels_raw, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addfe1e2",
   "metadata": {},
   "source": [
    "## Step 3 â€” Crop panels and run bubble OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a470c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image as PILImage\n",
    "\n",
    "panels_dir = Path(STORAGE) / COMIC_ID / 'panels'\n",
    "panels_dir.mkdir(exist_ok=True)\n",
    "\n",
    "BUBBLE_PROMPT = '''\n",
    "You are a comic OCR specialist. For each bubble return ONLY a JSON array.\n",
    "Each element: {\"order\": int, \"type\": str, \"x\": int, \"y\": int, \"w\": int, \"h\": int, \"text\": str, \"confidence\": float}\n",
    "Types: speech, thought, narration, sfx.\n",
    "'''\n",
    "\n",
    "all_bubbles = []\n",
    "page_img = PILImage.open(str(page_path))\n",
    "\n",
    "for p in sorted(panels_raw, key=lambda d: d['order']):\n",
    "    crop = page_img.crop((p['x'], p['y'], p['x']+p['w'], p['y']+p['h']))\n",
    "    panel_file = panels_dir / f\"panel_{p['order']:03d}.png\"\n",
    "    crop.save(str(panel_file), 'PNG')\n",
    "\n",
    "    b64p = encode_image(str(panel_file))\n",
    "    raw = chat(VISION_MODEL, [\n",
    "        {'role': 'system', 'content': BUBBLE_PROMPT},\n",
    "        {'role': 'user', 'content': [\n",
    "            {'type': 'image_url', 'image_url': {'url': f'data:image/png;base64,{b64p}'}},\n",
    "            {'type': 'text', 'text': 'Extract all bubbles and their text.'}\n",
    "        ]}\n",
    "    ])\n",
    "    if raw.startswith('```'): raw = raw.split('```')[1].lstrip('json').strip()\n",
    "    bubbles = json.loads(raw)\n",
    "    for b in bubbles:\n",
    "        b['panel_order'] = p['order']\n",
    "    all_bubbles.extend(bubbles)\n",
    "    print(f\"Panel {p['order']}: {len(bubbles)} bubbles\")\n",
    "\n",
    "print(json.dumps(all_bubbles, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b29f5f",
   "metadata": {},
   "source": [
    "## Step 4 â€” Speaker attribution + voice assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d5ef86",
   "metadata": {},
   "outputs": [],
   "source": [
    "ATTR_PROMPT = '''\n",
    "You are a comic character recognition agent. Attribute each bubble to a speaker.\n",
    "Return ONLY: {\"attributions\": [{\"bubble_id\": str, \"speaker_id\": str, \"label\": str}],\n",
    "              \"new_speakers\": [{\"speaker_id\": str, \"label\": str, \"gender\": str, \"age_group\": str}]}\n",
    "Use \\\"narrator\\\" for narration boxes. Reuse known speaker IDs when the same character reappears.\n",
    "'''\n",
    "\n",
    "VOICE_MAP = {\n",
    "    ('male','child'): 'verse', ('male','teen'): 'verse', ('male','adult'): 'echo', ('male','elder'): 'onyx',\n",
    "    ('female','child'): 'coral', ('female','teen'): 'coral', ('female','adult'): 'nova', ('female','elder'): 'shimmer',\n",
    "    ('unknown','adult'): 'alloy',\n",
    "}\n",
    "\n",
    "known_speakers = []\n",
    "\n",
    "for p in sorted(panels_raw, key=lambda d: d['order']):\n",
    "    panel_file = panels_dir / f\"panel_{p['order']:03d}.png\"\n",
    "    panel_bubbles = [b for b in all_bubbles if b['panel_order'] == p['order']]\n",
    "    bubble_list = [{'bubble_id': f\"p{p['order']}_b{b['order']}\", 'text': b['text'], 'type': b['type']} for b in panel_bubbles]\n",
    "\n",
    "    b64p = encode_image(str(panel_file))\n",
    "    raw = chat(VISION_MODEL, [\n",
    "        {'role': 'system', 'content': ATTR_PROMPT},\n",
    "        {'role': 'user', 'content': [\n",
    "            {'type': 'image_url', 'image_url': {'url': f'data:image/png;base64,{b64p}'}},\n",
    "            {'type': 'text', 'text': json.dumps({'known_speakers': [{'speaker_id': s['speaker_id'], 'label': s['label']} for s in known_speakers], 'bubbles': bubble_list})}\n",
    "        ]}\n",
    "    ])\n",
    "    if raw.startswith('```'): raw = raw.split('```')[1].lstrip('json').strip()\n",
    "    attr_data = json.loads(raw)\n",
    "\n",
    "    for attr in attr_data.get('attributions', []):\n",
    "        for b in all_bubbles:\n",
    "            if f\"p{p['order']}_b{b['order']}\" == attr['bubble_id']:\n",
    "                b['speaker_id'] = attr['speaker_id']\n",
    "\n",
    "    existing_ids = {s['speaker_id'] for s in known_speakers}\n",
    "    for ns in attr_data.get('new_speakers', []):\n",
    "        if ns['speaker_id'] not in existing_ids:\n",
    "            ns['voice_id'] = VOICE_MAP.get((ns.get('gender','unknown'), ns.get('age_group','adult')), 'alloy')\n",
    "            known_speakers.append(ns)\n",
    "\n",
    "print('Speakers:', json.dumps(known_speakers, indent=2))\n",
    "print('Attributed bubbles:', json.dumps(all_bubbles, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc75829",
   "metadata": {},
   "source": [
    "## Step 5 â€” Emotion tagging + TTS generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4970bec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TTS_MODEL = 'openai/gpt-audio-mini'\n",
    "voice_dir = Path(STORAGE) / COMIC_ID / 'audio' / 'voice'\n",
    "voice_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "EMOTION_PROMPT = '''\n",
    "Infer emotion per bubble. Return ONLY a JSON array:\n",
    "[{\"bubble_id\": str, \"emotion\": str}]\n",
    "Emotions: neutral, happy, sad, angry, excited, scared, surprised, sarcastic, whispering, shouting.\n",
    "'''\n",
    "\n",
    "speaker_map = {s['speaker_id']: s['label'] for s in known_speakers}\n",
    "bubble_list_for_emotion = [{'bubble_id': f\"p{b['panel_order']}_b{b['order']}\", 'text': b['text'], 'speaker': speaker_map.get(b.get('speaker_id',''), 'unknown')} for b in all_bubbles if b.get('text','').strip()]\n",
    "\n",
    "raw = chat(VISION_MODEL, [\n",
    "    {'role': 'system', 'content': EMOTION_PROMPT},\n",
    "    {'role': 'user', 'content': json.dumps(bubble_list_for_emotion)}\n",
    "])\n",
    "if raw.startswith('```'): raw = raw.split('```')[1].lstrip('json').strip()\n",
    "emotion_data = json.loads(raw)\n",
    "emotion_map = {e['bubble_id']: e['emotion'] for e in emotion_data}\n",
    "\n",
    "for b in all_bubbles:\n",
    "    bid = f\"p{b['panel_order']}_b{b['order']}\"\n",
    "    b['emotion'] = emotion_map.get(bid, 'neutral')\n",
    "\n",
    "# Generate TTS\n",
    "voice_lookup = {s['speaker_id']: s['voice_id'] for s in known_speakers}\n",
    "\n",
    "for b in all_bubbles:\n",
    "    if not b.get('text', '').strip() or b.get('type') == 'sfx': continue\n",
    "    voice_id = voice_lookup.get(b.get('speaker_id', ''), 'alloy')\n",
    "    out_path = voice_dir / f\"p{b['panel_order']}_b{b['order']}.mp3\"\n",
    "    r = httpx.post(f'{OR_BASE}/audio/speech', headers=HEADERS, timeout=120,\n",
    "                   json={'model': TTS_MODEL, 'input': b['text'], 'voice': voice_id,\n",
    "                         'instructions': f\"Speak with a {b['emotion']} tone.\", 'response_format': 'mp3'})\n",
    "    r.raise_for_status()\n",
    "    out_path.write_bytes(r.content)\n",
    "    b['audio_path'] = str(out_path)\n",
    "    print(f\"  [{b['emotion']}] {b['text'][:50]!r} â†’ {out_path.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4a726e",
   "metadata": {},
   "source": [
    "## Step 6 â€” SFX generation (Audiocraft AudioGen)\n",
    "\n",
    "Uses `facebook/audiogen-small` (~300 MB) â€” small enough to run comfortably on **both CPU and GPU**.\n",
    "\n",
    "| Mode | When to use | Speed |\n",
    "|---|---|---|\n",
    "| **GPU** (`cuda`) | Colab T4 runtime â€” *Runtime â†’ Change runtime type â†’ T4 GPU* | ~4 s per panel |\n",
    "| **CPU** (`cpu`) | Free Colab CPU runtime or when no GPU is available | ~15â€“25 s per panel |\n",
    "\n",
    "Set `AUDIOCRAFT_DEVICE` in the config cell above to `'auto'` (default), `'cuda'`, or `'cpu'`.\n",
    "\n",
    "Outputs are converted from WAV â†’ 128 kbps MP3 via ffmpeg then the WAV is deleted to reclaim disk space.  \n",
    "Model weights are cached under `/content/audiocraft_cache` (outside the home partition) to avoid quota issues.  \n",
    "Weights are re-downloaded each session (~300 MB) unless you persist that folder to Google Drive.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f61d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, subprocess, torch\n",
    "from pathlib import Path\n",
    "from audiocraft.models import AudioGen\n",
    "from audiocraft.data.audio import audio_write\n",
    "\n",
    "# â”€â”€ Resolve device from the config cell setting â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "if AUDIOCRAFT_DEVICE == 'auto':\n",
    "    _device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "elif AUDIOCRAFT_DEVICE == 'cuda':\n",
    "    if not torch.cuda.is_available():\n",
    "        print('âš ï¸  CUDA requested but no GPU found â€” falling back to CPU.')\n",
    "        print('    To use a GPU: Runtime â†’ Change runtime type â†’ T4 GPU')\n",
    "        _device = 'cpu'\n",
    "    else:\n",
    "        _device = 'cuda'\n",
    "else:\n",
    "    _device = 'cpu'\n",
    "\n",
    "print(f'Audiocraft device: {_device}')\n",
    "\n",
    "# â”€â”€ Redirect model weights away from the home-partition quota â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "os.environ['AUDIOCRAFT_CACHE_DIR'] = '/content/audiocraft_cache'\n",
    "os.makedirs('/content/audiocraft_cache', exist_ok=True)\n",
    "\n",
    "# â”€â”€ Load model (audiogen-small â‰ˆ 300 MB â€” fits on T4 and runs fine on CPU) â”€\n",
    "print('Loading facebook/audiogen-small â€¦')\n",
    "sfx_model = AudioGen.get_pretrained('facebook/audiogen-small', device=_device)\n",
    "sfx_model.set_generation_params(duration=4)   # 4 s per panel: sufficient & saves VRAM/disk\n",
    "print('Model ready.')\n",
    "\n",
    "# â”€â”€ Build one SFX prompt per panel via Gemini â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "SFX_PROMPT = '''\n",
    "You are a comic sound-design director. For each panel image produce a short, vivid\n",
    "audio description suitable as a text-to-audio prompt (â‰¤ 12 words).\n",
    "Return ONLY a JSON object: {\"panel_<order>\": \"<prompt>\", ...}\n",
    "Focus on ambient mood + key action sounds. Avoid music references.\n",
    "'''\n",
    "\n",
    "sfx_prompts: dict[str, str] = {}\n",
    "for p in sorted(panels_raw, key=lambda d: d['order']):\n",
    "    panel_file = panels_dir / f\"panel_{p['order']:03d}.png\"\n",
    "    b64p = encode_image(str(panel_file))\n",
    "    raw = chat(VISION_MODEL, [\n",
    "        {'role': 'system', 'content': SFX_PROMPT},\n",
    "        {'role': 'user', 'content': [\n",
    "            {'type': 'image_url', 'image_url': {'url': f'data:image/png;base64,{b64p}'}},\n",
    "            {'type': 'text', 'text': 'Describe the soundscape for this panel.'}\n",
    "        ]}\n",
    "    ])\n",
    "    if raw.startswith('```'):\n",
    "        raw = raw.split('```')[1].lstrip('json').strip()\n",
    "    try:\n",
    "        sfx_prompts.update(json.loads(raw))\n",
    "    except json.JSONDecodeError:\n",
    "        sfx_prompts[f'panel_{p[\"order\"]}'] = 'soft ambient background, comic book atmosphere'\n",
    "\n",
    "print('SFX prompts:', json.dumps(sfx_prompts, indent=2))\n",
    "\n",
    "# â”€â”€ Generate audio + convert WAV â†’ MP3 (saves â‰ˆ 60 % disk) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "sfx_dir = Path(STORAGE) / COMIC_ID / 'audio' / 'sfx'\n",
    "sfx_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for p in sorted(panels_raw, key=lambda d: d['order']):\n",
    "    key      = f'panel_{p[\"order\"]}'\n",
    "    prompt   = sfx_prompts.get(key, 'soft ambient background, comic book atmosphere')\n",
    "    stem     = str(sfx_dir / f'panel_{p[\"order\"]:03d}')\n",
    "    wav_path = Path(stem + '.wav')\n",
    "    mp3_path = Path(stem + '.mp3')\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        wav = sfx_model.generate([prompt])   # shape: (1, channels, samples)\n",
    "\n",
    "    # audio_write appends '.wav' automatically\n",
    "    audio_write(\n",
    "        stem, wav[0].cpu(), sfx_model.sample_rate,\n",
    "        strategy='loudness', loudness_compressor=True\n",
    "    )\n",
    "\n",
    "    # Convert to MP3 and remove the WAV to save disk\n",
    "    result = subprocess.run(\n",
    "        ['ffmpeg', '-y', '-i', str(wav_path), '-b:a', '128k', str(mp3_path)],\n",
    "        capture_output=True\n",
    "    )\n",
    "    if result.returncode == 0 and wav_path.exists():\n",
    "        wav_path.unlink()\n",
    "        final_path = str(mp3_path)\n",
    "    else:\n",
    "        final_path = str(wav_path)   # keep WAV if ffmpeg failed\n",
    "\n",
    "    p['sfx_path'] = final_path\n",
    "    print(f'Panel {p[\"order\"]:2d}: {Path(final_path).name}  |  prompt: {prompt!r}')\n",
    "\n",
    "print('\\nSFX generation complete.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ad7d1c",
   "metadata": {},
   "source": [
    "## Step 7 â€” Playback test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ea2764",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio as IPAudio, display, Image as IPImage\n",
    "\n",
    "for p in sorted(panels_raw, key=lambda d: d['order']):\n",
    "    panel_file = panels_dir / f\"panel_{p['order']:03d}.png\"\n",
    "    print(f'\\n=== Panel {p[\"order\"]} ===')\n",
    "    display(IPImage(str(panel_file), width=500))\n",
    "\n",
    "    # SFX track for this panel\n",
    "    if p.get('sfx_path') and Path(p['sfx_path']).exists():\n",
    "        print(f'  ğŸ”Š SFX: {Path(p[\"sfx_path\"]).name}')\n",
    "        display(IPAudio(p['sfx_path']))\n",
    "\n",
    "    # Dialogue / narration bubbles\n",
    "    panel_bubbles = sorted(\n",
    "        [b for b in all_bubbles if b['panel_order'] == p['order']],\n",
    "        key=lambda x: x['order']\n",
    "    )\n",
    "    for b in panel_bubbles:\n",
    "        if b.get('audio_path') and Path(b['audio_path']).exists():\n",
    "            print(f'  ğŸ—¨  [{b.get(\"speaker_id\",\"?\")}] [{b[\"emotion\"]}] {b[\"text\"]}')\n",
    "            display(IPAudio(b['audio_path']))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
