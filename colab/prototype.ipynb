{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27721f48",
   "metadata": {},
   "source": [
    "# Comikry â€” Colab Prototype\n",
    "End-to-end pipeline validation on a single comic page.\n",
    "\n",
    "**Run cells top-to-bottom.** Cell 2 clones the latest repo code automatically.\n",
    "\n",
    "**API key setup (once):**\n",
    "- **VS Code** â€” copy `.env.example` â†’ `.env` in the repo root and fill in `OPENROUTER_API_KEY`\n",
    "- **Colab browser** â€” left sidebar â†’ ğŸ”‘ *Secrets* â†’ *Add new secret* â†’ name: `OPENROUTER_API_KEY`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc4f07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "REPO_URL  = 'https://github.com/LIdro/comikry.git'\n",
    "REPO_DIR  = Path('/content/comikry')\n",
    "\n",
    "if REPO_DIR.exists():\n",
    "    # Already cloned â€” pull latest changes\n",
    "    print('â–º Pulling latest changes â€¦')\n",
    "    os.system(f'git -C {REPO_DIR} pull --ff-only')\n",
    "else:\n",
    "    print('â–º Cloning comikry repo â€¦')\n",
    "    os.system(f'git clone --depth 1 {REPO_URL} {REPO_DIR}')\n",
    "\n",
    "# Add repo root to the Python path so backend modules are importable if needed\n",
    "import sys\n",
    "if str(REPO_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(REPO_DIR))\n",
    "\n",
    "print(f'âœ…  Repo ready at {REPO_DIR}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b638f69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ System packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# ffmpeg: WAV â†’ MP3 conversion (saves ~60 % disk vs keeping WAV)\n",
    "# poppler-utils: required by pdf2image to render PDF pages\n",
    "!apt-get install -q -y ffmpeg poppler-utils\n",
    "\n",
    "# â”€â”€ Python packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "!pip install -q pdf2image Pillow httpx python-ulid pydantic pydantic-settings\n",
    "\n",
    "# â”€â”€ Audiocraft â€” install from source (the PyPI wheel build is broken on\n",
    "#    Colab's Python 3.11 + modern pip; source install always works) â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# gradio is pinned because newer versions break the Audiocraft demo UI;\n",
    "# we don't use the UI here but the pin avoids dependency conflicts.\n",
    "!pip install -q 'torch>=2.0' 'torchaudio>=2.0'\n",
    "!pip install -q git+https://github.com/facebookresearch/audiocraft.git\n",
    "!pip install -q gradio==4.44.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2c650d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# â”€â”€ Load API key â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Supports two environments automatically:\n",
    "#\n",
    "#   VS Code  â†’ reads from the root .env  (copy .env.example â†’ .env and fill in key)\n",
    "#   Colab    â†’ reads from the ğŸ”‘ Secrets panel (left sidebar â†’ Add new secret)\n",
    "#\n",
    "def _load_api_key() -> str:\n",
    "    # Candidate .env locations (checked in order):\n",
    "    #   1. Repo root when cloned to /content/comikry  (Colab)\n",
    "    #   2. Repo root when opened locally in VS Code   (two levels up from colab/)\n",
    "    #   3. Current working directory fallback\n",
    "    candidates = [\n",
    "        Path('/content/comikry/.env'),               # Colab after git clone\n",
    "        Path(__file__).resolve().parents[1] / '.env' # local: colab/../.env\n",
    "        if '__file__' in dir() else None,\n",
    "        Path('.env'),                                 # cwd fallback\n",
    "    ]\n",
    "\n",
    "    for env_file in candidates:\n",
    "        if env_file and env_file.exists():\n",
    "            for line in env_file.read_text().splitlines():\n",
    "                line = line.strip()\n",
    "                if line.startswith('OPENROUTER_API_KEY=') and not line.startswith('#'):\n",
    "                    key = line.split('=', 1)[1].strip()\n",
    "                    if key and key != 'your_openrouter_api_key_here':\n",
    "                        print(f'ğŸ”‘  API key loaded from {env_file}')\n",
    "                        return key\n",
    "\n",
    "    # Fall back to Colab Secrets (browser Colab without a local .env)\n",
    "    try:\n",
    "        from google.colab import userdata\n",
    "        key = userdata.get('OPENROUTER_API_KEY')\n",
    "        if key:\n",
    "            print('ğŸ”‘  API key loaded from Colab Secrets')\n",
    "            return key\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Already set in the process environment\n",
    "    key = os.environ.get('OPENROUTER_API_KEY', '')\n",
    "    if key:\n",
    "        print('ğŸ”‘  API key loaded from environment variable')\n",
    "        return key\n",
    "\n",
    "    raise EnvironmentError(\n",
    "        'OPENROUTER_API_KEY not found.\\n'\n",
    "        '  VS Code : copy .env.example â†’ .env in the repo root and fill in the key.\\n'\n",
    "        '  Colab   : left sidebar â†’ ğŸ”‘ Secrets â†’ Add new secret â†’ OPENROUTER_API_KEY'\n",
    "    )\n",
    "\n",
    "os.environ['OPENROUTER_API_KEY'] = _load_api_key()\n",
    "\n",
    "# â”€â”€ Comic / run settings â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "PDF_PATH   = 'comic.pdf'   # â† set the filename of the PDF you uploaded\n",
    "PAGE_NUM   = 1             # page to process (1-based)\n",
    "COMIC_ID   = 'colab_test'\n",
    "STORAGE    = '/content/storage'\n",
    "os.makedirs(STORAGE, exist_ok=True)\n",
    "\n",
    "# â”€â”€ Audiocraft device â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 'auto' â†’ CUDA if a GPU runtime is active, otherwise CPU (recommended)\n",
    "# 'cuda' â†’ force GPU  (Runtime â†’ Change runtime type â†’ T4 GPU)\n",
    "# 'cpu'  â†’ force CPU  (works on any runtime, ~3â€“5Ã— slower for audiogen-small)\n",
    "AUDIOCRAFT_DEVICE = 'auto'   # â† change to 'cuda' or 'cpu' to override\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bee836",
   "metadata": {},
   "source": [
    "## Step 1 â€” Render PDF page to PNG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08f4942",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "from pathlib import Path\n",
    "\n",
    "pages_dir = Path(STORAGE) / COMIC_ID / 'pages'\n",
    "pages_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "pages = convert_from_path(PDF_PATH, dpi=150, fmt='png')\n",
    "page_path = pages_dir / f'page_{PAGE_NUM:04d}.png'\n",
    "pages[PAGE_NUM - 1].save(str(page_path), 'PNG')\n",
    "print(f'Saved page image: {page_path}')\n",
    "\n",
    "from IPython.display import display, Image as IPImage\n",
    "display(IPImage(str(page_path), width=600))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d9b7b2",
   "metadata": {},
   "source": [
    "## Step 2 â€” Detect panels with Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f687291a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64, json, httpx\n",
    "\n",
    "OPENROUTER_KEY  = os.environ['OPENROUTER_API_KEY']\n",
    "VISION_MODEL    = 'google/gemini-2.5-flash-lite'\n",
    "OR_BASE         = 'https://openrouter.ai/api/v1'\n",
    "HEADERS         = {'Authorization': f'Bearer {OPENROUTER_KEY}', 'Content-Type': 'application/json'}\n",
    "\n",
    "def encode_image(path):\n",
    "    return base64.b64encode(open(path, 'rb').read()).decode()\n",
    "\n",
    "def chat(model, messages):\n",
    "    r = httpx.post(f'{OR_BASE}/chat/completions',\n",
    "                   headers=HEADERS, json={'model': model, 'messages': messages}, timeout=120)\n",
    "    r.raise_for_status()\n",
    "    return r.json()['choices'][0]['message']['content'].strip()\n",
    "\n",
    "PANEL_PROMPT = '''\n",
    "You are a comic panel analyser. Return ONLY a JSON array of panels in reading order.\n",
    "Each element: {\"order\": int, \"x\": int, \"y\": int, \"w\": int, \"h\": int}\n",
    "'''\n",
    "\n",
    "b64 = encode_image(str(page_path))\n",
    "raw = chat(VISION_MODEL, [\n",
    "    {'role': 'system', 'content': PANEL_PROMPT},\n",
    "    {'role': 'user', 'content': [\n",
    "        {'type': 'image_url', 'image_url': {'url': f'data:image/png;base64,{b64}'}},\n",
    "        {'type': 'text', 'text': 'Detect all panels.'}\n",
    "    ]}\n",
    "])\n",
    "\n",
    "if raw.startswith('```'): raw = raw.split('```')[1].lstrip('json').strip()\n",
    "panels_raw = json.loads(raw)\n",
    "print(f'Found {len(panels_raw)} panels:', json.dumps(panels_raw, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addfe1e2",
   "metadata": {},
   "source": [
    "## Step 3 â€” Crop panels and run bubble OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a470c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image as PILImage\n",
    "\n",
    "panels_dir = Path(STORAGE) / COMIC_ID / 'panels'\n",
    "panels_dir.mkdir(exist_ok=True)\n",
    "\n",
    "BUBBLE_PROMPT = '''\n",
    "You are a comic OCR specialist. For each bubble return ONLY a JSON array.\n",
    "Each element: {\"order\": int, \"type\": str, \"x\": int, \"y\": int, \"w\": int, \"h\": int, \"text\": str, \"confidence\": float}\n",
    "Types: speech, thought, narration, sfx.\n",
    "'''\n",
    "\n",
    "all_bubbles = []\n",
    "page_img = PILImage.open(str(page_path))\n",
    "\n",
    "for p in sorted(panels_raw, key=lambda d: d['order']):\n",
    "    crop = page_img.crop((p['x'], p['y'], p['x']+p['w'], p['y']+p['h']))\n",
    "    panel_file = panels_dir / f\"panel_{p['order']:03d}.png\"\n",
    "    crop.save(str(panel_file), 'PNG')\n",
    "\n",
    "    b64p = encode_image(str(panel_file))\n",
    "    raw = chat(VISION_MODEL, [\n",
    "        {'role': 'system', 'content': BUBBLE_PROMPT},\n",
    "        {'role': 'user', 'content': [\n",
    "            {'type': 'image_url', 'image_url': {'url': f'data:image/png;base64,{b64p}'}},\n",
    "            {'type': 'text', 'text': 'Extract all bubbles and their text.'}\n",
    "        ]}\n",
    "    ])\n",
    "    if raw.startswith('```'): raw = raw.split('```')[1].lstrip('json').strip()\n",
    "    bubbles = json.loads(raw)\n",
    "    for b in bubbles:\n",
    "        b['panel_order'] = p['order']\n",
    "    all_bubbles.extend(bubbles)\n",
    "    print(f\"Panel {p['order']}: {len(bubbles)} bubbles\")\n",
    "\n",
    "print(json.dumps(all_bubbles, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b29f5f",
   "metadata": {},
   "source": [
    "## Step 4 â€” Speaker attribution + voice assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d5ef86",
   "metadata": {},
   "outputs": [],
   "source": [
    "ATTR_PROMPT = '''\n",
    "You are a comic character recognition agent. Attribute each bubble to a speaker.\n",
    "Return ONLY: {\"attributions\": [{\"bubble_id\": str, \"speaker_id\": str, \"label\": str}],\n",
    "              \"new_speakers\": [{\"speaker_id\": str, \"label\": str, \"gender\": str, \"age_group\": str}]}\n",
    "Use \\\"narrator\\\" for narration boxes. Reuse known speaker IDs when the same character reappears.\n",
    "'''\n",
    "\n",
    "VOICE_MAP = {\n",
    "    ('male','child'): 'verse', ('male','teen'): 'verse', ('male','adult'): 'echo', ('male','elder'): 'onyx',\n",
    "    ('female','child'): 'coral', ('female','teen'): 'coral', ('female','adult'): 'nova', ('female','elder'): 'shimmer',\n",
    "    ('unknown','adult'): 'alloy',\n",
    "}\n",
    "\n",
    "known_speakers = []\n",
    "\n",
    "for p in sorted(panels_raw, key=lambda d: d['order']):\n",
    "    panel_file = panels_dir / f\"panel_{p['order']:03d}.png\"\n",
    "    panel_bubbles = [b for b in all_bubbles if b['panel_order'] == p['order']]\n",
    "    bubble_list = [{'bubble_id': f\"p{p['order']}_b{b['order']}\", 'text': b['text'], 'type': b['type']} for b in panel_bubbles]\n",
    "\n",
    "    b64p = encode_image(str(panel_file))\n",
    "    raw = chat(VISION_MODEL, [\n",
    "        {'role': 'system', 'content': ATTR_PROMPT},\n",
    "        {'role': 'user', 'content': [\n",
    "            {'type': 'image_url', 'image_url': {'url': f'data:image/png;base64,{b64p}'}},\n",
    "            {'type': 'text', 'text': json.dumps({'known_speakers': [{'speaker_id': s['speaker_id'], 'label': s['label']} for s in known_speakers], 'bubbles': bubble_list})}\n",
    "        ]}\n",
    "    ])\n",
    "    if raw.startswith('```'): raw = raw.split('```')[1].lstrip('json').strip()\n",
    "    attr_data = json.loads(raw)\n",
    "\n",
    "    for attr in attr_data.get('attributions', []):\n",
    "        for b in all_bubbles:\n",
    "            if f\"p{p['order']}_b{b['order']}\" == attr['bubble_id']:\n",
    "                b['speaker_id'] = attr['speaker_id']\n",
    "\n",
    "    existing_ids = {s['speaker_id'] for s in known_speakers}\n",
    "    for ns in attr_data.get('new_speakers', []):\n",
    "        if ns['speaker_id'] not in existing_ids:\n",
    "            ns['voice_id'] = VOICE_MAP.get((ns.get('gender','unknown'), ns.get('age_group','adult')), 'alloy')\n",
    "            known_speakers.append(ns)\n",
    "\n",
    "print('Speakers:', json.dumps(known_speakers, indent=2))\n",
    "print('Attributed bubbles:', json.dumps(all_bubbles, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc75829",
   "metadata": {},
   "source": [
    "## Step 5 â€” Emotion tagging + TTS generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4970bec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TTS_MODEL = 'openai/gpt-audio-mini'\n",
    "voice_dir = Path(STORAGE) / COMIC_ID / 'audio' / 'voice'\n",
    "voice_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "EMOTION_PROMPT = '''\n",
    "Infer emotion per bubble. Return ONLY a JSON array:\n",
    "[{\"bubble_id\": str, \"emotion\": str}]\n",
    "Emotions: neutral, happy, sad, angry, excited, scared, surprised, sarcastic, whispering, shouting.\n",
    "'''\n",
    "\n",
    "speaker_map = {s['speaker_id']: s['label'] for s in known_speakers}\n",
    "bubble_list_for_emotion = [{'bubble_id': f\"p{b['panel_order']}_b{b['order']}\", 'text': b['text'], 'speaker': speaker_map.get(b.get('speaker_id',''), 'unknown')} for b in all_bubbles if b.get('text','').strip()]\n",
    "\n",
    "raw = chat(VISION_MODEL, [\n",
    "    {'role': 'system', 'content': EMOTION_PROMPT},\n",
    "    {'role': 'user', 'content': json.dumps(bubble_list_for_emotion)}\n",
    "])\n",
    "if raw.startswith('```'): raw = raw.split('```')[1].lstrip('json').strip()\n",
    "emotion_data = json.loads(raw)\n",
    "emotion_map = {e['bubble_id']: e['emotion'] for e in emotion_data}\n",
    "\n",
    "for b in all_bubbles:\n",
    "    bid = f\"p{b['panel_order']}_b{b['order']}\"\n",
    "    b['emotion'] = emotion_map.get(bid, 'neutral')\n",
    "\n",
    "# Generate TTS\n",
    "voice_lookup = {s['speaker_id']: s['voice_id'] for s in known_speakers}\n",
    "\n",
    "for b in all_bubbles:\n",
    "    if not b.get('text', '').strip() or b.get('type') == 'sfx': continue\n",
    "    voice_id = voice_lookup.get(b.get('speaker_id', ''), 'alloy')\n",
    "    out_path = voice_dir / f\"p{b['panel_order']}_b{b['order']}.mp3\"\n",
    "    r = httpx.post(f'{OR_BASE}/audio/speech', headers=HEADERS, timeout=120,\n",
    "                   json={'model': TTS_MODEL, 'input': b['text'], 'voice': voice_id,\n",
    "                         'instructions': f\"Speak with a {b['emotion']} tone.\", 'response_format': 'mp3'})\n",
    "    r.raise_for_status()\n",
    "    out_path.write_bytes(r.content)\n",
    "    b['audio_path'] = str(out_path)\n",
    "    print(f\"  [{b['emotion']}] {b['text'][:50]!r} â†’ {out_path.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4a726e",
   "metadata": {},
   "source": [
    "## Step 6 â€” SFX generation (Audiocraft AudioGen)\n",
    "\n",
    "Uses `facebook/audiogen-small` (~300 MB) â€” small enough to run comfortably on **both CPU and GPU**.\n",
    "\n",
    "| Mode | When to use | Speed |\n",
    "|---|---|---|\n",
    "| **GPU** (`cuda`) | Colab T4 runtime â€” *Runtime â†’ Change runtime type â†’ T4 GPU* | ~4 s per panel |\n",
    "| **CPU** (`cpu`) | Free Colab CPU runtime or when no GPU is available | ~15â€“25 s per panel |\n",
    "\n",
    "Set `AUDIOCRAFT_DEVICE` in the config cell above to `'auto'` (default), `'cuda'`, or `'cpu'`.\n",
    "\n",
    "Outputs are converted from WAV â†’ 128 kbps MP3 via ffmpeg then the WAV is deleted to reclaim disk space.  \n",
    "Model weights are cached under `/content/audiocraft_cache` (outside the home partition) to avoid quota issues.  \n",
    "Weights are re-downloaded each session (~300 MB) unless you persist that folder to Google Drive.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f61d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, subprocess, torch\n",
    "from pathlib import Path\n",
    "from audiocraft.models import AudioGen\n",
    "from audiocraft.data.audio import audio_write\n",
    "\n",
    "# â”€â”€ Resolve device from the config cell setting â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "if AUDIOCRAFT_DEVICE == 'auto':\n",
    "    _device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "elif AUDIOCRAFT_DEVICE == 'cuda':\n",
    "    if not torch.cuda.is_available():\n",
    "        print('âš ï¸  CUDA requested but no GPU found â€” falling back to CPU.')\n",
    "        print('    To use a GPU: Runtime â†’ Change runtime type â†’ T4 GPU')\n",
    "        _device = 'cpu'\n",
    "    else:\n",
    "        _device = 'cuda'\n",
    "else:\n",
    "    _device = 'cpu'\n",
    "\n",
    "print(f'Audiocraft device: {_device}')\n",
    "\n",
    "# â”€â”€ Redirect model weights away from the home-partition quota â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "os.environ['AUDIOCRAFT_CACHE_DIR'] = '/content/audiocraft_cache'\n",
    "os.makedirs('/content/audiocraft_cache', exist_ok=True)\n",
    "\n",
    "# â”€â”€ Load model (audiogen-small â‰ˆ 300 MB â€” fits on T4 and runs fine on CPU) â”€\n",
    "print('Loading facebook/audiogen-small â€¦')\n",
    "sfx_model = AudioGen.get_pretrained('facebook/audiogen-small', device=_device)\n",
    "sfx_model.set_generation_params(duration=4)   # 4 s per panel: sufficient & saves VRAM/disk\n",
    "print('Model ready.')\n",
    "\n",
    "# â”€â”€ Build one SFX prompt per panel via Gemini â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "SFX_PROMPT = '''\n",
    "You are a comic sound-design director. For each panel image produce a short, vivid\n",
    "audio description suitable as a text-to-audio prompt (â‰¤ 12 words).\n",
    "Return ONLY a JSON object: {\"panel_<order>\": \"<prompt>\", ...}\n",
    "Focus on ambient mood + key action sounds. Avoid music references.\n",
    "'''\n",
    "\n",
    "sfx_prompts: dict[str, str] = {}\n",
    "for p in sorted(panels_raw, key=lambda d: d['order']):\n",
    "    panel_file = panels_dir / f\"panel_{p['order']:03d}.png\"\n",
    "    b64p = encode_image(str(panel_file))\n",
    "    raw = chat(VISION_MODEL, [\n",
    "        {'role': 'system', 'content': SFX_PROMPT},\n",
    "        {'role': 'user', 'content': [\n",
    "            {'type': 'image_url', 'image_url': {'url': f'data:image/png;base64,{b64p}'}},\n",
    "            {'type': 'text', 'text': 'Describe the soundscape for this panel.'}\n",
    "        ]}\n",
    "    ])\n",
    "    if raw.startswith('```'):\n",
    "        raw = raw.split('```')[1].lstrip('json').strip()\n",
    "    try:\n",
    "        sfx_prompts.update(json.loads(raw))\n",
    "    except json.JSONDecodeError:\n",
    "        sfx_prompts[f'panel_{p[\"order\"]}'] = 'soft ambient background, comic book atmosphere'\n",
    "\n",
    "print('SFX prompts:', json.dumps(sfx_prompts, indent=2))\n",
    "\n",
    "# â”€â”€ Generate audio + convert WAV â†’ MP3 (saves â‰ˆ 60 % disk) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "sfx_dir = Path(STORAGE) / COMIC_ID / 'audio' / 'sfx'\n",
    "sfx_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for p in sorted(panels_raw, key=lambda d: d['order']):\n",
    "    key      = f'panel_{p[\"order\"]}'\n",
    "    prompt   = sfx_prompts.get(key, 'soft ambient background, comic book atmosphere')\n",
    "    stem     = str(sfx_dir / f'panel_{p[\"order\"]:03d}')\n",
    "    wav_path = Path(stem + '.wav')\n",
    "    mp3_path = Path(stem + '.mp3')\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        wav = sfx_model.generate([prompt])   # shape: (1, channels, samples)\n",
    "\n",
    "    # audio_write appends '.wav' automatically\n",
    "    audio_write(\n",
    "        stem, wav[0].cpu(), sfx_model.sample_rate,\n",
    "        strategy='loudness', loudness_compressor=True\n",
    "    )\n",
    "\n",
    "    # Convert to MP3 and remove the WAV to save disk\n",
    "    result = subprocess.run(\n",
    "        ['ffmpeg', '-y', '-i', str(wav_path), '-b:a', '128k', str(mp3_path)],\n",
    "        capture_output=True\n",
    "    )\n",
    "    if result.returncode == 0 and wav_path.exists():\n",
    "        wav_path.unlink()\n",
    "        final_path = str(mp3_path)\n",
    "    else:\n",
    "        final_path = str(wav_path)   # keep WAV if ffmpeg failed\n",
    "\n",
    "    p['sfx_path'] = final_path\n",
    "    print(f'Panel {p[\"order\"]:2d}: {Path(final_path).name}  |  prompt: {prompt!r}')\n",
    "\n",
    "print('\\nSFX generation complete.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ad7d1c",
   "metadata": {},
   "source": [
    "## Step 7 â€” Playback test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ea2764",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio as IPAudio, display, Image as IPImage\n",
    "\n",
    "for p in sorted(panels_raw, key=lambda d: d['order']):\n",
    "    panel_file = panels_dir / f\"panel_{p['order']:03d}.png\"\n",
    "    print(f'\\n=== Panel {p[\"order\"]} ===')\n",
    "    display(IPImage(str(panel_file), width=500))\n",
    "\n",
    "    # SFX track for this panel\n",
    "    if p.get('sfx_path') and Path(p['sfx_path']).exists():\n",
    "        print(f'  ğŸ”Š SFX: {Path(p[\"sfx_path\"]).name}')\n",
    "        display(IPAudio(p['sfx_path']))\n",
    "\n",
    "    # Dialogue / narration bubbles\n",
    "    panel_bubbles = sorted(\n",
    "        [b for b in all_bubbles if b['panel_order'] == p['order']],\n",
    "        key=lambda x: x['order']\n",
    "    )\n",
    "    for b in panel_bubbles:\n",
    "        if b.get('audio_path') and Path(b['audio_path']).exists():\n",
    "            print(f'  ğŸ—¨  [{b.get(\"speaker_id\",\"?\")}] [{b[\"emotion\"]}] {b[\"text\"]}')\n",
    "            display(IPAudio(b['audio_path']))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
